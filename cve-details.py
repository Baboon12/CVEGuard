import requests
from bs4 import BeautifulSoup
import pandas as pd


basic_url = "https//cve.mitre.org"

base_url = "https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=kaspersky"


url = base_url

response = requests.get(url)

if response.status_code == 200:
    soup = BeautifulSoup(response.content, "html.parser")
    table = soup.find('div', {'id': 'TableWithRules'}).find('table')
    if table:
        data = []
        rows = table.find_all('tr')

        for row in rows:
            tds = row.find_all('td')
            if len(tds) >= 2:
                title_element = tds[0].find('a')
                link = title_element['href'] if title_element else ''
                title = title_element.get_text().strip() if title_element else ''
                if title and link:
                    data.append({'CVE ID': title, 'Link': basic_url + link})
                    # print(f"Title: {title}\nLink: {basic_url + link}\n")
        if data:
            # Create a DataFrame
            df = pd.DataFrame(data)

            # Save to an Excel file
            df.to_excel('cve_data.xlsx', index=False)

            print('Data exported to cve_data.xlsx')
        else:
            print('No CVE IDs and Links Found')
    else:
        print('No Table WithRules Found')
else:
    print("Failed to retrieve the page. Status code:", response.status_code)
